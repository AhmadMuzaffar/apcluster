\documentclass[article]{bioinf}

\usepackage[noae]{Sweave}
\usepackage{amsmath,amssymb}
\usepackage{hyperref}

\hypersetup{colorlinks=false,
   pdfborder=0 0 0,
   pdftitle={APCluster - An R Package for Affinity Propagation Clustering},
   pdfauthor={Ulrich Bodenhofer}}

\title{An R Package for Affinity Propagation Clustering}
\author{Ulrich Bodenhofer and Andreas Kothmeier}
\affiliation{Institute of Bioinformatics, Johannes Kepler University
Linz\\Altenberger Str. 69, 4040 Linz, Austria\\
\email{apcluster@bioinf.jku.at}}

\newcommand{\APCluster}{\texttt{apcluster}}
\newcommand{\R}{R}
\newcommand{\Real}{\mathbb{R}}

\renewcommand{\vec}[1]{\mathbf{#1}}

\setkeys{Gin}{width=0.55\textwidth}

% \VignetteIndexEntry{An R Package for Affinity Propagation Clustering}
% \VignetteDepends{methods, stats, graphics, utils}

\SweaveOpts{eps=FALSE}

\begin{document}
<<echo=FALSE>>=
options(width=75)
set.seed(0)
library(apcluster)
apclusterver<-packageDescription("apcluster")$Version
@
\newcommand{\APClusterVer}{\Sexpr{apclusterver}}
\manualtitlepage[Version \APClusterVer, \today]

\section*{Scope and Purpose of this Document}

This document is a user manual for the \R\ package \APCluster.
It is only meant as a gentle introduction into how to use the basic
functions implemented in this package. Not all features of the \R\
package are described in full detail. Such details can be obtained
from the documentation enclosed in the  \R\ package. Further note
the following: (1) this is neither an introduction to affinity propagation
nor to clustering in general; (2) this is not an introduction to \R.
If you lack the background for understanding this manual, you first
have to read introductory literature on these subjects.

\vspace{1cm}

\newlength{\auxparskip}
\setlength{\auxparskip}{\parskip}
\setlength{\parskip}{0pt}
\tableofcontents
\clearpage
\setlength{\parskip}{\auxparskip}

\newlength{\Nboxwidth}
\setlength{\Nboxwidth}{\textwidth}
\addtolength{\Nboxwidth}{-2\fboxrule}
\addtolength{\Nboxwidth}{-2\fboxsep}

\newcommand{\notebox}[1]{%
\begin{center}
\fbox{\begin{minipage}{\Nboxwidth}
\noindent{\sffamily\bfseries Note:} #1
\end{minipage}}
\end{center}}

\section{Introduction}

Affinity propagation (AP) is a relatively new clustering algorithm
that has been introduced by Brendan~J.~Frey and Delbert~Dueck
\cite{FreyDueck07}.\footnotemark[1]\footnotetext[1]{\url{http://www.psi.toronto.edu/affinitypropagation/}}\stepcounter{footnote}
The authors themselves describe affinity propagation as
follows:\footnote{quoted from
\url{http://www.psi.toronto.edu/affinitypropagation/faq.html\#def}}

\begin{quote}
``{\em An algorithm that identifies
exemplars among data points and forms clusters of data points
around these exemplars. It operates by simultaneously
considering all data point as potential exemplars and
exchanging messages between data points until a good set of
exemplars and clusters emerges.}''
\end{quote}

AP has been applied in various fields recently, among which bioinformatics
is becoming increasingly important. Frey and Dueck have made their algorithm
available as Matlab code.\footnotemark[1] Matlab,
however, is relatively uncommon in bioinformatics. Instead, the statistical
computing platform \R\ has become a widely accepted standard in this field.
In order to leverage affinity propagation for bioinformatics applications,
we have implemented affinity propagation as an \R\ package.
Note, however, that the given package is in no way restricted
to bioinformatics applications. It is as generally applicable as Frey's and
Dueck's original Matlab code.\footnotemark[1]


\section{Installation} 

\subsection{Installation via CRAN}

The \R\ package \APCluster\ (current version: \APClusterVer) is
part of the {\em Comprehensive R Archive Network (CRAN)}%
\footnote{\url{http://cran.r-project.org/}}. The simplest way to install the
package, therefore, is to enter the following command into your \R\ session:
<<eval=FALSE>>=
install.packages("apcluster")
@

\subsection{Manual installation}

If, for what reason ever, you prefer to install the package manually, download
the package file suitable for your computer system and copy it to your harddisk.
Open the package's page at CRAN%
\footnote{\url{http://cran.r-project.org/web/packages/apcluster/index.html}} and
the proceed as follows.

\subsubsection*{Manual installation under Windows}

\begin{enumerate}
\item Download \texttt{apcluster\_\APClusterVer.zip}
and save it to your harddisk
\item Open the \R\ GUI and select the menu entry
\begin{quote}
\ttfamily Packages | Install package(s) from local zip files...
\end{quote}
In the file dialog that opens, go to the folder where you placed
{\ttfamily apcluster\_\APClusterVer.zip} and select this file. The
package should be installed now.
\end{enumerate}

\subsubsection*{Manual installation under Linux/UNIX/MacOS}
\begin{enumerate}
\item Download \texttt{apcluster\_\APClusterVer.tar.gz}
and save it to your harddisk.
\item Open a shell window and change to the directory where you put {\ttfamily apcluster\_\APClusterVer.tar.gz}. Enter
\begin{quote}
\ttfamily R CMD INSTALL apcluster\_\APClusterVer.tar.gz
\end{quote}
to install the package.
\end{enumerate}

\subsection{Compatibility Issues}

Both the Windows and the Linux/UNIX/MacOS version of the package
have been built under \R\ 2.10.1, but have been tested with earlier
\R\ versions too. Apart from installation warnings that the package
has been built with a more recent version of \R, it should work
without severe problems on \R\ versions $\geq$2.6.1.

\section{Getting Started}

To load the package, enter the following in your \R\ session:
<<eval=FALSE>>=
library(apcluster)
@
If this command terminates without any error
message or warning, you can be sure that the package has
been installed successfully. If so, the package is ready
for use now and you can start clustering your data with affinity propagation.

The package includes both a user manual (this document) and a reference manual
(help pages for each function). To view the user manual, enter
<<eval=FALSE>>=
vignette("APCluster-Manual")
@
Help pages can be viewed using the \verb+help+ command. It is recommended to
start with
<<eval=FALSE>>=
help(apcluster)
@ 

Affinity propagation does not require the data samples to be of any
specific kind or structure. AP only requires a {\em similarity matrix}, i.e.,
given $l$ data samples, this is an $l\times l$ real-valued matrix $\mathbf{S}$,
in which an entry $S_{ij}$ corresponds to a value measuring how similar
sample $i$ is to sample $j$. AP does not require these values to be in a
specific range. Values can be positive or negative. AP does not
even require the similarity matrix to be symmetric (although, in most
applications, it will be symmetric anyway). A value of $-\infty$ is interpreted
as ``absolute dissimilarity''. The higher a value, the more similar two samples
are considered.

To get a first impression, let us create a random data set in
$\Real^2$ as the union of two ``Gaussian clouds'':
\begin{center}
<<fig=TRUE,echo=TRUE,width=5,height=5>>=
cl1 <- cbind(rnorm(30, 0.3, 0.05), rnorm(30, 0.7, 0.04))
cl2 <- cbind(rnorm(30, 0.7, 0.04), rnorm(30, 0.4, .05))
x <- rbind(cl1, cl2)
plot(x, xlab="", ylab="", pch=19, cex=0.8)
@
\end{center}
Now we have to create a similarity matrix. The package \APCluster\ offers
several different ways for doing that (see Section~\ref{sec:DistMat} below).
Let us start with the default similarity measure used in the papers of Frey
and Dueck --- negative squared distances:
<<>>=
s <- negDistMat(x, r=2)
@ 
We are now ready to run affinity propagation:
<<>>=
apres <- apcluster(s)
@ 
The function \verb+apcluster+ creates an object belonging to the S4
class \verb+APResult+ that is defined by the present package. To get
detailed information on which data are stored in such objects, enter
<<eval=FALSE>>=
help(APResult)
@
The simplest thing we can do with the output is to enter the name of the
object (which implicitly calls \verb+show+) to get a summary of the
clustering result:
<<>>=
apres
@
For two-dimensional data sets, \APCluster\ allows for plotting the
original data set along with a clustering result:
\begin{center}
<<fig=TRUE,echo=TRUE,width=5,height=5>>=
plot(apres, x)
@
\end{center}
In this plot, each color corresponds to one cluster. The exemplar of each
cluster is marked by a box and all cluster members are connected to their
exemplars with lines.

Suppose we want to have better insight into what the algorithm did in each
iteration. For this purpose, we can supply the option \verb+details=TRUE+
to \verb+apcluster+:
<<>>=
apres <- apcluster(s, details=TRUE)
@ 
This option tells the algorithm to keep a detailed log about its progress.
For example, this allows us to plot the three performance measures that AP
uses internally for each iteration:
\begin{center}
<<fig=TRUE,echo=TRUE,width=6,height=4>>=
plot(apres)
@ 
\end{center}
These performance measures are:
\begin{enumerate}
\item Sum of exemplar preferences
\item Sum of similarities of exemplars to their cluster members
\item Net fitness: sum of the two former
\end{enumerate}
For details, the user is referred to the original affinity propagation
paper \cite{FreyDueck07} and the supplementary material published on the
affinity propagation Web page.\footnotemark[1] We see
from the above plot that the algorithm has not made any change for the last 100
(of \Sexpr{apres@it}!) iterations. AP, through its parameter
\verb+convits+, allows to
control for how long AP waits for a change until it terminates (the default is
\verb+convits=100+). If the user has the feeling that AP will probably
converge quicker on his/her data set, a lower value can be used:
<<>>=
apres <- apcluster(s, convits=15, details=TRUE)
apres
@

\section{Adjusting Input Preferences}

Apart from the similarity itself, the most important input parameter of
AP is the so-called {\em input preference} which can be interpreted as the
tendency of a data sample to become an exemplar (see \cite{FreyDueck07} and 
supplementary material on the AP homepage\footnotemark[1] for a more detailed
explanation). This input preference can either be chosen individually for
each data sample or it can be a single value shared among all data samples.
Input preferences largely determine the number of clusters,
in other words, how fine- or coarse-grained the clustering result will be.

The input preferences one can specify for AP are roughly in the same range
as the similarity values, but they do not have a straightforward interpretation.
Frey and Dueck have introduced the following rule of thumb: ``{\it The shared
value could be the median of the input similarities (resulting in a moderate
number of clusters) or their minimum (resulting in a small number of
clusters).}'' \cite{FreyDueck07}

Our AP implementation uses the median rule by default if the user does not
supply a custom value for the input preferences. In order to provide the user
with a knob that is --- at least to some extent --- interpretable, the function
\verb+apcluster+ has a new argument \verb+q+ that allows to set the input
preference to a certain quantile of the input similarities: resulting in the
median for \verb+q=0.5+ and in the minimum for \verb+q=0+. As an example, let
us add two more ``clouds'' to the data set from above:
\begin{center}
<<fig=TRUE,echo=TRUE,width=5,height=5>>=
cl3 <- cbind(rnorm(20, 0.50, 0.03), rnorm(20, 0.72, 0.03))
cl4 <- cbind(rnorm(25, 0.50, 0.03), rnorm(25, 0.42, 0.04))
x <- rbind(x, cl3, cl4)
s <- negDistMat(x, r=2)
plot(x, xlab="", ylab="", pch=19, cex=0.8)
@
\end{center}
For the default setting, we obtain the following result:
\begin{center}
<<fig=TRUE,echo=TRUE,width=5,height=5>>=
apres <- apcluster(s)
plot(apres, x)
@ 
\end{center}
For the minimum of input similarities, we obtain the following result:
\begin{center}
<<fig=TRUE,echo=TRUE,width=5,height=5>>=
apres <- apcluster(s, q=0)
plot(apres, x)
@ 
\end{center}
So we see that AP is quite robust against a reduction of input preferences
in this example which may be caused by the clear separation of the four
clusters. If we increase input preferences, however, we can force AP to
split the four clusters into smaller sub-clusters:
<<>>=
apres <- apcluster(s, q=0.8)
@
\begin{center}
<<fig=TRUE,echo=TRUE,width=5,height=5>>=
plot(apres, x)
@ 
\end{center}

Note that the input preference used by AP can be recovered from the output
object (no matter which method to adjust input preferences has been used).
On the one hand, the value is printed if the object is displayed
(by \verb+show+ or by entering the output object's name). On the other hand,
the value can be accessed directly via the slot \verb+p+:
<<>>=
apres@p
@

The above example with \verb+q=0+ demonstrates that setting
input preferences to the minimum of input similarities does not necessarily
result in a very small number of clusters (like one or two). This is due to the
fact that input preferences need not necessarily be exactly in the range of the
similarities. To determine a meaningful range, an auxiliary function is
available which, in line with Frey's and Dueck's Matlab code,\footnotemark[1]
allows to compute
a minimum value (for which one or at most two clusters would be obtained)
and a maximum value (for which as many clusters as data samples would be
obtained):
<<>>=
preferenceRange(s)
@
The function returns a two-element vector with the minimum value as first and
the maximum value as second entry. The computations are done approximately
by default. If one is interested in exact bounds, supply \verb+exact=TRUE+
(resulting in longer computation times). 

Many clustering algorithms need to know a pre-defined number of clusters. This
is often a major nuisance, since the exact number of clusters is hard to know
for non-trivial (in particular, high-dimensional) data sets. AP avoids this
problem. If, however, one still wants to require a fixed number of clusters,
this has to be accomplished by a search algorithm that adjusts input preferences
in order to produce the desired number of clusters in the end. For convenience,
this search algorithm is available as a function \verb+apclusterK+ (analogous
to Frey's and Dueck's Matlab implementation\footnotemark[1]).
We can use this function to
force AP to produce only two clusters (merging the two pairs of adjacent
clouds into one cluster each):
\begin{center}
<<fig=TRUE,echo=TRUE,width=5,height=5>>=
apres <- apclusterK(s, 2)
plot(apres, x)
@
\end{center}

\section{Similarity Matrices}\label{sec:DistMat}

Apart from the obvious monotonicity ``the higher the value, the more similar two
samples'', affinity propagation does not make any specific assumption about
the similarity measure. Negative squared distances must be used if one wants
to minimize squared errors \cite{FreyDueck07}. Apart from that, the choice and
implementation of the similarity measure is left to the user.

Our package offers a few more methods to obtain similarity matrices.
The choice of the right one (and, consequently, the objective function the
algorithm optimizes), still has to be made by the user.

\subsection{The function \texttt{negDistMat}}

The function \verb+negDistMat+, in line with Frey and Dueck, allows to compute
negative distances for a given set of real-valued data samples. Above we have
used the following:
<<eval=FALSE>>=
s <- negDistMat(x, r=2)
@
This computes a matrix of negative squared distances from the data matrix
\verb+x+. The function \texttt{negDistMat} is a simple wrapper around the
standard function \verb+dist+, hence, it allows for a lot more different
similarity measures. The user can make use of all variants implemented in
\verb+dist+ by
using the options \verb+method+ (selects a distance measure) and \verb+p+
(specifies the exponent for the Minkowski distance, otherwise it is void) that
are passed on to \verb+dist+. Presently, \verb+dist+ provides the following variants of computing the distance $d(\vec{x},\vec{y})$ of two data samples
$\vec{x}=(x_1,\dots,x_d)$ and $\vec{y}=(y_1,\dots,y_d)$:
\begin{description}
\item[Euclidean:]
\[
d(\vec{x},\vec{y})=\sqrt{\sum\limits_{i=1}^d (x_i-y_i)^2}
\]
use \verb+method="euclidean"+ or do not specify argument \verb+method+
(since this is the default);
\item[Maximum:]
\[
d(\vec{x},\vec{y})=\max\limits_{i=1}^d |x_i-y_i|
\]
use \verb+method="maximum"+;
\item[Sum of absolute distances / Manhattan:]
\[
d(\vec{x},\vec{y})=\sum\limits_{i=1}^d |x_i-y_i|
\]
use \verb+method="manhattan"+;
\item[Canberra:]
\[
d(\vec{x},\vec{y})=\sum\limits_{i=1}^d \frac{|x_i-y_i|}{|x_i+y_i|}
\]
summands with zero denominators are not taken into account;
use \verb+method="canberra"+;
\item[Minkowski:]
\[
d(\vec{x},\vec{y})=\left(\sum\limits_{i=1}^d (x_i-y_i)^p\right)^{\frac{1}{p}}
\]
use \verb+method="minkowski"+ and specify $p$ using the additional argument
$\verb+p+$ (default is \verb+p=2+, resulting in the standard Euclidean
distance);
\end{description}
We do not consider \verb+method="binary"+ here, since it is irrelevant for
real-valued data.

The function \verb+negDistMat+ takes the distances computed with one of the
variants listed above and returns $-1$ times the $r$-th power of it, i.e.,
\begin{equation}\label{eq:negDistMat}
s(\vec{x},\vec{y})=-d(\vec{x},\vec{y})^r.
\end{equation}
The exponent $r$ can be adjusted with the argument \verb+r+. The default is
\verb+r=1+, hence, one has to supply \verb+r=2+ as in the above example to
obtain squared distances.

Here are some examples. We use the corners of the two-dimensional unit square
and its middle point $(\frac{1}{2},\frac{1}{2})$ as sample data:
<<>>=
ex <- matrix(c(0,0,1,0,0.5,0.5,0,1,1,1),5,2,byrow=TRUE)
ex
@ 
Standard Euclidean distance:
<<>>=
negDistMat(ex)
@
Squared Euclidean distance:
<<>>=
negDistMat(ex, r=2)
@
Maximum norm-based distance:
<<>>=
negDistMat(ex,method="maximum")
@
Sum of absolute distances (aka Manhattan distance):
<<>>=
negDistMat(ex,method="manhattan")
@
Canberra distance:
<<>>=
negDistMat(ex,method="canberra")
@
Minkowski distance for $p=3$ ($3$-norm):
<<>>=
negDistMat(ex, method="minkowski", p=3)
@

\subsection{Other similarity measures}

The package \APCluster\ offers three more functions for creating similarity
matrices for real-valued data:

\begin{description}
\item[Exponential transformation of distances:] the function \verb+expSimMat+
is another wrapper around the standard function \verb+dist+. The difference is
that, instead of the transformation \eqref{eq:negDistMat}, it uses the
following transformation:
\[
s(\vec{x},\vec{y})=\exp\left(-\left(\frac{d(\vec{x},\vec{y})}{w}\right)^r\right)
\]
Here the default is \verb+r=2+. It is clear that \verb+r=2+ in conjunction with
\verb+method="euclidean"+ results in the well-known
{\em Gaussian kernel / RBF kernel}
\cite{FitzGeraldMicchelliPinkus95,Micchelli86,SchoelkopfSmola02}, whereas
\verb+r=1+ in conjunction with
\verb+method="euclidean"+ results in the similarity measure that is sometimes
called {\em Laplace kernel} \cite{FitzGeraldMicchelliPinkus95,Micchelli86}.
Both variants (for non-Euclidean distances as well) can also be interpreted
as {\em fuzzy equality/similarity relations}
\cite{DeBaetsMesiar02}.
\item[Linear scaling of distances with truncation:]
the function \verb+linSimMat+ uses the transformation
\[
s(\vec{x},\vec{y})=\max\left(1-\frac{d(\vec{x},\vec{y})}{w},0\right)
\]
which is also often interpreted as a {\em fuzzy equality/similarity relation}
\cite{DeBaetsMesiar02}.
\item[Linear kernel:] scalar products can also be interpreted as similarity
measures, a view that is often adopted by kernel methods in machine learning.
In order to provide the user with this option as well, the function
\verb+linKernel+ is available. For two data samples 
$\vec{x}=(x_1,\dots,x_d)$ and
$\vec{y}=(y_1,\dots,y_d)$, it computes the similarity as
\[
s(\vec{x},\vec{y})=\sum\limits_{i=1}^d x_i\cdot y_i.
\]
The function has one additional argument, \verb+normalize+ (by default
\verb+FALSE+). If \verb+normalize=TRUE+, values are normalized to the range
$[-1,+1]$ in the following way:
\[
s(\vec{x},\vec{y})=\frac{\sum_{i=1}^d x_i\cdot y_i}%
{\sqrt{\big(\sum_{i=1}^d x_i^2\big)\cdot%
\big(\sum_{i=1}^d y_i^2\big)}}
\]
Entries for which at least one of the two factors in the denominator
is zero are set
to zero (however, the user should be aware that this should be avoided
anyway).
\end{description}

For the same example data as above, we obtain the
following for the RBF kernel:
<<>>=
expSimMat(ex)
@
Laplace kernel:
<<>>=
expSimMat(ex, r=1)
@
Linear scaling of distances with truncation:
<<>>=
linSimMat(ex, w=1.2)
@
Linear kernel (we exclude $(0,0)$):
<<>>=
linKernel(ex[2:5,])
@
Normalized linear kernel (we exclude $(0,0)$):
<<>>=
linKernel(ex[2:5,], normalize=TRUE)
@

\section{Known Issues / Future Extensions}

\begin{itemize}
\item We currently have no implementation that exploits sparsity of similarity
matrices. The implementation of {\em sparse AP} and {\em leveraged AP} which
are available as Matlab code from the AP Web page\footnotemark[1] is left
for future extensions of the package. Presently, we only offer a function
\verb+sparseToFull+ that converts similarity matrices from sparse format into
a full $l\times l$ matrix.
\item We are aware that our \R\ implementation is often slower than Frey's and
Dueck's Matlab code.\footnotemark[1] We have no sufficiently convincing
explanation for this at the moment.
\end{itemize}

\section{How to Cite This Package}

If you use this package for research that is published later, you are kindly
asked to cite it as follows:
\begin{quotation}
\noindent U.~Bodenhofer and A.~Kothmeier (2010).
An R package for affinity propagation clustering.
R package version \APClusterVer.
Institute of Bioinformatics, Johannes Kepler University, Linz, Austria.
\end{quotation}
Moreover, we insist that, any time you cite the package, you also cite the
original paper in which affinity propagation has been introduced
\cite{FreyDueck07}.

To obtain Bib\TeX\ entries of the two references, you can enter the following
into your R session:
<<eval=FALSE>>=
toBibtex(citation("apcluster"))
@ 

%\bibliographystyle{plain}
%\bibliography{Bioinformatics,MachineLearningClassical,%
%MathematicsMisc,FuzzySetsRelations}

\begin{thebibliography}{1}

\bibitem{FreyDueck07}
B.~J. Frey and D.~Dueck.
\newblock Clustering by passing messages between data points.
\newblock {\em Science}, 315(5814):972--976, 2007.

\bibitem{FitzGeraldMicchelliPinkus95}
C.~H. FitzGerald, C.~A. Micchelli, and A.~Pinkus.
\newblock Functions that preserve families of positive semidefinite matrices.
\newblock {\em Linear Alg. Appl.}, 221:83--102, 1995.

\bibitem{Micchelli86}
C.~A. Micchelli.
\newblock Interpolation of scattered data: Distance matrices and conditionally
  positive definite functions.
\newblock {\em Constr. Approx.}, 2:11--22, 1986.

\bibitem{SchoelkopfSmola02}
B.~Sch\"olkopf and A.~J. Smola.
\newblock {\em Learning with Kernels}.
\newblock Adaptive Computation and Machine Learning. MIT Press, Cambridge, MA,
  2002.

\bibitem{DeBaetsMesiar02}
B.~{De Baets} and R.~Mesiar.
\newblock Metrics and {$T$}-equalities.
\newblock {\em J. Math. Anal. Appl.}, 267:531--547, 2002.

\end{thebibliography}


\end{document}
